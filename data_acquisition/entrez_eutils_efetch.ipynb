{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "\n",
    "# Define the URLs and parameters for the data\n",
    "bioproject_id = \"PRJNA288601\"\n",
    "efetch_bioproject_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "efetch_biosample_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "\n",
    "# Fetch the isolate data from the BioProject\n",
    "efetch_params = {\n",
    "    \"db\": \"bioproject\",\n",
    "    \"id\": bioproject_id,\n",
    "    \"retmode\": \"xml\"\n",
    "}\n",
    "response = requests.get(efetch_bioproject_url, params=efetch_params)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Parse the BioProject XML content\n",
    "root = ET.fromstring(response.content)\n",
    "isolates = root.findall(\".//ProjectDescr/LocusTagPrefix\")\n",
    "\n",
    "# Parse each isolate to get biosample_id and locus_tag_prefix\n",
    "parsed_isolates = []\n",
    "for isolate in isolates:\n",
    "    biosample_id = isolate.attrib.get('biosample_id')\n",
    "    locus_tag_prefix = isolate.text\n",
    "    if biosample_id and locus_tag_prefix:\n",
    "        parsed_isolates.append({\n",
    "            'biosample_id': biosample_id,\n",
    "            'locus_tag_prefix': locus_tag_prefix\n",
    "        })\n",
    "\n",
    "# Check the initial number of isolates\n",
    "print(f\"Number of parsed isolates: {len(parsed_isolates)}\")\n",
    "\n",
    "# Randomly select 20 biosample IDs for testing\n",
    "sample_size = 20\n",
    "sample_isolates = random.sample(parsed_isolates, sample_size)\n",
    "\n",
    "# Function to parse additional data\n",
    "def parse_additional_data(biosample_root):\n",
    "    data = {\n",
    "        'biosample_id': biosample_root.findtext(\".//Ids/Id[@db='BioSample']\"),\n",
    "        'organism_group': biosample_root.findtext(\".//Organism/OrganismName\"),\n",
    "        'strain': biosample_root.findtext(\".//Attribute[@attribute_name='strain']\"),\n",
    "        'isolate_identifiers': biosample_root.findtext(\".//Ids/Id[@db_label='Sample name']\"),\n",
    "        'serovar': biosample_root.findtext(\".//Attribute[@attribute_name='serovar']\"),\n",
    "        'isolate': biosample_root.findtext(\".//Attribute[@attribute_name='isolate']\"),\n",
    "        'create_date': biosample_root.find(\".//Status[@status='live']\").attrib.get('when') if biosample_root.find(\".//Status[@status='live']\") is not None else None,\n",
    "        'location': biosample_root.findtext(\".//Attribute[@attribute_name='geo_loc_name']\"),\n",
    "        'isolation_source': biosample_root.findtext(\".//Attribute[@attribute_name='isolation_source']\"),\n",
    "        'isolation_type': biosample_root.findtext(\".//Attribute[@attribute_name='isolation_type']\"),\n",
    "        'food_origin': biosample_root.findtext(\".//Attribute[@attribute_name='food_origin']\"),\n",
    "        'snp_cluster': biosample_root.findtext(\".//Attribute[@attribute_name='snp_cluster']\"),\n",
    "        'min_same': biosample_root.findtext(\".//Attribute[@attribute_name='min-same']\"),\n",
    "        'min_diff': biosample_root.findtext(\".//Attribute[@attribute_name='min-diff']\"),\n",
    "        'assembly': biosample_root.findtext(\".//Attribute[@attribute_name='assembly']\"),\n",
    "        'amr_genotypes': biosample_root.findtext(\".//Attribute[@attribute_name='amr_genotypes']\"),  # Check for AMR genotypes\n",
    "        'computed_types': biosample_root.findtext(\".//Attribute[@attribute_name='computed_types']\"),\n",
    "        'host': biosample_root.findtext(\".//Attribute[@attribute_name='host']\"),\n",
    "        'collection_date': biosample_root.findtext(\".//Attribute[@attribute_name='collection_date']\"),\n",
    "        'mlst': biosample_root.findtext(\".//Attribute[@attribute_name='MLST']\"),\n",
    "        'sample_type': biosample_root.findtext(\".//Attribute[@attribute_name='sample_type']\"),\n",
    "        'collected_by': biosample_root.findtext(\".//Attribute[@attribute_name='collected_by']\"),\n",
    "        'host_disease': biosample_root.findtext(\".//Attribute[@attribute_name='host_disease']\"),\n",
    "        'lat_lon': biosample_root.findtext(\".//Attribute[@attribute_name='lat_lon']\"),\n",
    "        'sequenced_by': biosample_root.findtext(\".//Attribute[@attribute_name='sequenced_by']\")\n",
    "    }\n",
    "    # Remove keys with None values\n",
    "    data = {k: v for k, v in data.items() if v is not None}\n",
    "    return data\n",
    "\n",
    "# Fetch additional data for the selected biosample_ids\n",
    "additional_data = []\n",
    "error_biosamples = []\n",
    "\n",
    "for isolate in sample_isolates:\n",
    "    biosample_id = isolate['biosample_id']\n",
    "    efetch_params = {\n",
    "        \"db\": \"biosample\",\n",
    "        \"id\": biosample_id,\n",
    "        \"retmode\": \"xml\"\n",
    "    }\n",
    "    response = requests.get(efetch_biosample_url, params=efetch_params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data for biosample_id: {biosample_id}\")\n",
    "        error_biosamples.append(biosample_id)\n",
    "        continue\n",
    "    \n",
    "    # Parse the biosample XML content\n",
    "    biosample_root = ET.fromstring(response.content)\n",
    "    \n",
    "    # Extract additional data\n",
    "    biosample_data = parse_additional_data(biosample_root)\n",
    "    \n",
    "    # Check if extracted data contains None values and log missing fields\n",
    "    missing_fields = [k for k, v in biosample_data.items() if v is None]\n",
    "    if missing_fields:\n",
    "        print(f\"Incomplete data for biosample_id: {biosample_id}, missing fields: {missing_fields}\")\n",
    "        error_biosamples.append(biosample_id)\n",
    "    else:\n",
    "        additional_data.append(biosample_data)\n",
    "\n",
    "# Convert parsed isolates and additional data to DataFrames\n",
    "\n",
    "df_sample_isolates = pd.DataFrame(sample_isolates)\n",
    "df_additional_data = pd.DataFrame(additional_data)\n",
    "\n",
    "# Merge the two DataFrames on biosample_id\n",
    "df_merged = pd.merge(df_sample_isolates, df_additional_data, on=\"biosample_id\", how=\"left\")\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "output_file = \"isolates_sample_detailed.csv\"\n",
    "df_merged.to_csv(output_file, index=False)\n",
    "\n",
    "# Log the final number of records\n",
    "print(f\"Final number of records in CSV: {len(df_merged)}\")\n",
    "\n",
    "# Output the path of the saved file for download\n",
    "output_file"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
